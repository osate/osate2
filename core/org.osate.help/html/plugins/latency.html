<!DOCTYPE html>
<html>
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
  <title>latency.html</title>
  <meta name="generator" content="Haroopad 0.13.1" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">

  <style>div.oembedall-githubrepos{border:1px solid #DDD;border-radius:4px;list-style-type:none;margin:0 0 10px;padding:8px 10px 0;font:13.34px/1.4 helvetica,arial,freesans,clean,sans-serif;width:452px;background-color:#fff}div.oembedall-githubrepos .oembedall-body{background:-moz-linear-gradient(center top,#FAFAFA,#EFEFEF);background:-webkit-gradient(linear,left top,left bottom,from(#FAFAFA),to(#EFEFEF));border-bottom-left-radius:4px;border-bottom-right-radius:4px;border-top:1px solid #EEE;margin-left:-10px;margin-top:8px;padding:5px 10px;width:100%}div.oembedall-githubrepos h3{font-size:14px;margin:0;padding-left:18px;white-space:nowrap}div.oembedall-githubrepos p.oembedall-description{color:#444;font-size:12px;margin:0 0 3px}div.oembedall-githubrepos p.oembedall-updated-at{color:#888;font-size:11px;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats{border:none;float:right;font-size:11px;font-weight:700;padding-left:15px;position:relative;z-index:5;margin:0}div.oembedall-githubrepos ul.oembedall-repo-stats li{border:none;color:#666;display:inline-block;list-style-type:none;margin:0!important}div.oembedall-githubrepos ul.oembedall-repo-stats li a{background-color:transparent;border:none;color:#666!important;background-position:5px -2px;background-repeat:no-repeat;border-left:1px solid #DDD;display:inline-block;height:21px;line-height:21px;padding:0 5px 0 23px}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a{border-left:medium none;margin-right:-3px}div.oembedall-githubrepos ul.oembedall-repo-stats li a:hover{background:5px -27px no-repeat #4183C4;color:#FFF!important;text-decoration:none}div.oembedall-githubrepos ul.oembedall-repo-stats li:first-child a:hover{border-bottom-left-radius:3px;border-top-left-radius:3px}ul.oembedall-repo-stats li:last-child a:hover{border-bottom-right-radius:3px;border-top-right-radius:3px}span.oembedall-closehide{background-color:#aaa;border-radius:2px;cursor:pointer;margin-right:3px}div.oembedall-container{margin-top:5px;text-align:left}.oembedall-ljuser{font-weight:700}.oembedall-ljuser img{vertical-align:bottom;border:0;padding-right:1px}.oembedall-stoqembed{border-bottom:1px dotted #999;float:left;overflow:hidden;width:730px;line-height:1;background:#FFF;color:#000;font-family:Arial,Liberation Sans,DejaVu Sans,sans-serif;font-size:80%;text-align:left;margin:0;padding:0}.oembedall-stoqembed a{color:#07C;text-decoration:none;margin:0;padding:0}.oembedall-stoqembed a:hover{text-decoration:underline}.oembedall-stoqembed a:visited{color:#4A6B82}.oembedall-stoqembed h3{font-family:Trebuchet MS,Liberation Sans,DejaVu Sans,sans-serif;font-size:130%;font-weight:700;margin:0;padding:0}.oembedall-stoqembed .oembedall-reputation-score{color:#444;font-size:120%;font-weight:700;margin-right:2px}.oembedall-stoqembed .oembedall-user-info{height:35px;width:185px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-gravatar32{float:left;height:32px;width:32px}.oembedall-stoqembed .oembedall-user-info .oembedall-user-details{float:left;margin-left:5px;overflow:hidden;white-space:nowrap;width:145px}.oembedall-stoqembed .oembedall-question-hyperlink{font-weight:700}.oembedall-stoqembed .oembedall-stats{background:#EEE;margin:0 0 0 7px;padding:4px 7px 6px;width:58px}.oembedall-stoqembed .oembedall-statscontainer{float:left;margin-right:8px;width:86px}.oembedall-stoqembed .oembedall-votes{color:#555;padding:0 0 7px;text-align:center}.oembedall-stoqembed .oembedall-vote-count-post{font-size:240%;color:#808185;display:block;font-weight:700}.oembedall-stoqembed .oembedall-views{color:#999;padding-top:4px;text-align:center}.oembedall-stoqembed .oembedall-status{margin-top:-3px;padding:4px 0;text-align:center;background:#75845C;color:#FFF}.oembedall-stoqembed .oembedall-status strong{color:#FFF;display:block;font-size:140%}.oembedall-stoqembed .oembedall-summary{float:left;width:635px}.oembedall-stoqembed .oembedall-excerpt{line-height:1.2;margin:0;padding:0 0 5px}.oembedall-stoqembed .oembedall-tags{float:left;line-height:18px}.oembedall-stoqembed .oembedall-tags a:hover{text-decoration:none}.oembedall-stoqembed .oembedall-post-tag{background-color:#E0EAF1;border-bottom:1px solid #3E6D8E;border-right:1px solid #7F9FB6;color:#3E6D8E;font-size:90%;line-height:2.4;margin:2px 2px 2px 0;padding:3px 4px;text-decoration:none;white-space:nowrap}.oembedall-stoqembed .oembedall-post-tag:hover{background-color:#3E6D8E;border-bottom:1px solid #37607D;border-right:1px solid #37607D;color:#E0EAF1}.oembedall-stoqembed .oembedall-fr{float:right}.oembedall-stoqembed .oembedall-statsarrow{background-image:url(http://cdn.sstatic.net/stackoverflow/img/sprites.png?v=3);background-repeat:no-repeat;overflow:hidden;background-position:0 -435px;float:right;height:13px;margin-top:12px;width:7px}.oembedall-facebook1{border:1px solid #1A3C6C;padding:0;font:13.34px/1.4 verdana;width:500px}.oembedall-facebook2{background-color:#627add}.oembedall-facebook2 a{color:#e8e8e8;text-decoration:none}.oembedall-facebookBody{background-color:#fff;vertical-align:top;padding:5px}.oembedall-facebookBody .contents{display:inline-block;width:100%}.oembedall-facebookBody div img{float:left;margin-right:5px}div.oembedall-lanyard{-webkit-box-shadow:none;-webkit-transition-delay:0s;-webkit-transition-duration:.4000000059604645s;-webkit-transition-property:width;-webkit-transition-timing-function:cubic-bezier(0.42,0,.58,1);background-attachment:scroll;background-clip:border-box;background-color:transparent;background-image:none;background-origin:padding-box;border-width:0;box-shadow:none;color:#112644;display:block;float:left;font-family:'Trebuchet MS',Trebuchet,sans-serif;font-size:16px;height:253px;line-height:19px;margin:0;max-width:none;min-height:0;outline:#112644 0;overflow-x:visible;overflow-y:visible;padding:0;position:relative;text-align:left;vertical-align:baseline;width:804px}div.oembedall-lanyard .tagline{font-size:1.5em}div.oembedall-lanyard .wrapper{overflow:hidden;clear:both}div.oembedall-lanyard .split{float:left;display:inline}div.oembedall-lanyard .prominent-place .flag:active,div.oembedall-lanyard .prominent-place .flag:focus,div.oembedall-lanyard .prominent-place .flag:hover,div.oembedall-lanyard .prominent-place .flag:link,div.oembedall-lanyard .prominent-place .flag:visited{float:left;display:block;width:48px;height:48px;position:relative;top:-5px;margin-right:10px}div.oembedall-lanyard .place-context{font-size:.889em}div.oembedall-lanyard .prominent-place .sub-place{display:block}div.oembedall-lanyard .prominent-place{font-size:1.125em;line-height:1.1em;font-weight:400}div.oembedall-lanyard .main-date{color:#8CB4E0;font-weight:700;line-height:1.1}div.oembedall-lanyard .first{width:48.57%;margin:0 0 0 2.857%}.mermaid .label{color:#333}.node circle,.node polygon,.node rect{fill:#cde498;stroke:#13540c;stroke-width:1px}.edgePath .path{stroke:green;stroke-width:1.5px}.cluster rect{fill:#cdffb2;rx:40;stroke:#6eaa49;stroke-width:1px}.cluster text{fill:#333}.actor{stroke:#13540c;fill:#cde498}text.actor{fill:#000;stroke:none}.actor-line{stroke:grey}.messageLine0{stroke-width:1.5;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#333}.messageLine1{stroke-width:1.5;stroke-dasharray:"2 2";stroke:#333}#arrowhead{fill:#333}#crosshead path{fill:#333!important;stroke:#333!important}.messageText{fill:#333;stroke:none}.labelBox{stroke:#326932;fill:#cde498}.labelText,.loopText{fill:#000;stroke:none}.loopLine{stroke-width:2;stroke-dasharray:"2 2";marker-end:"url(#arrowhead)";stroke:#326932}.note{stroke:#6eaa49;fill:#fff5ad}.noteText{fill:#000;stroke:none;font-family:'trebuchet ms',verdana,arial;font-size:14px}.section{stroke:none;opacity:.2}.section0,.section2{fill:#6eaa49}.section1,.section3{fill:#fff;opacity:.2}.sectionTitle0,.sectionTitle1,.sectionTitle2,.sectionTitle3{fill:#333}.sectionTitle{text-anchor:start;font-size:11px;text-height:14px}.grid .tick{stroke:lightgrey;opacity:.3;shape-rendering:crispEdges}.grid path{stroke-width:0}.today{fill:none;stroke:red;stroke-width:2px}.task{stroke-width:2}.taskText{text-anchor:middle;font-size:11px}.taskTextOutsideRight{fill:#000;text-anchor:start;font-size:11px}.taskTextOutsideLeft{fill:#000;text-anchor:end;font-size:11px}.taskText0,.taskText1,.taskText2,.taskText3{fill:#fff}.task0,.task1,.task2,.task3{fill:#487e3a;stroke:#13540c}.taskTextOutside0,.taskTextOutside1,.taskTextOutside2,.taskTextOutside3{fill:#000}.active0,.active1,.active2,.active3{fill:#cde498;stroke:#13540c}.activeText0,.activeText1,.activeText2,.activeText3{fill:#000!important}.done0,.done1,.done2,.done3{stroke:grey;fill:lightgrey;stroke-width:2}.doneText0,.doneText1,.doneText2,.doneText3{fill:#000!important}.crit0,.crit1,.crit2,.crit3{stroke:#f88;fill:red;stroke-width:2}.activeCrit0,.activeCrit1,.activeCrit2,.activeCrit3{stroke:#f88;fill:#cde498;stroke-width:2}.doneCrit0,.doneCrit1,.doneCrit2,.doneCrit3{stroke:#f88;fill:lightgrey;stroke-width:2;cursor:pointer;shape-rendering:crispEdges}.activeCritText0,.activeCritText1,.activeCritText2,.activeCritText3,.doneCritText0,.doneCritText1,.doneCritText2,.doneCritText3{fill:#000!important}.titleText{text-anchor:middle;font-size:18px;fill:#000}text{font-family:'trebuchet ms',verdana,arial;font-size:14px}html{height:100%}body{margin:0!important;padding:5px 20px 26px!important;background-color:#fff;font-family:"Lucida Grande","Segoe UI","Apple SD Gothic Neo","Malgun Gothic","Lucida Sans Unicode",Helvetica,Arial,sans-serif;font-size:.9em;overflow-x:hidden;overflow-y:auto}br,h1,h2,h3,h4,h5,h6{clear:both}hr.page{background:url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAYAAAAECAYAAACtBE5DAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyJpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuMC1jMDYwIDYxLjEzNDc3NywgMjAxMC8wMi8xMi0xNzozMjowMCAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENTNSBNYWNpbnRvc2giIHhtcE1NOkluc3RhbmNlSUQ9InhtcC5paWQ6OENDRjNBN0E2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiIHhtcE1NOkRvY3VtZW50SUQ9InhtcC5kaWQ6OENDRjNBN0I2NTZBMTFFMEI3QjRBODM4NzJDMjlGNDgiPiA8eG1wTU06RGVyaXZlZEZyb20gc3RSZWY6aW5zdGFuY2VJRD0ieG1wLmlpZDo4Q0NGM0E3ODY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIgc3RSZWY6ZG9jdW1lbnRJRD0ieG1wLmRpZDo4Q0NGM0E3OTY1NkExMUUwQjdCNEE4Mzg3MkMyOUY0OCIvPiA8L3JkZjpEZXNjcmlwdGlvbj4gPC9yZGY6UkRGPiA8L3g6eG1wbWV0YT4gPD94cGFja2V0IGVuZD0iciI/PqqezsUAAAAfSURBVHjaYmRABcYwBiM2QSA4y4hNEKYDQxAEAAIMAHNGAzhkPOlYAAAAAElFTkSuQmCC) repeat-x;border:0;height:3px;padding:0}hr.underscore{border-top-style:dashed!important}body >:first-child{margin-top:0!important}img.plugin{box-shadow:0 1px 3px rgba(0,0,0,.1);border-radius:3px}iframe{border:0}figure{-webkit-margin-before:0;-webkit-margin-after:0;-webkit-margin-start:0;-webkit-margin-end:0}kbd{border:1px solid #aaa;-moz-border-radius:2px;-webkit-border-radius:2px;border-radius:2px;-moz-box-shadow:1px 2px 2px #ddd;-webkit-box-shadow:1px 2px 2px #ddd;box-shadow:1px 2px 2px #ddd;background-color:#f9f9f9;background-image:-moz-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-o-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:-webkit-linear-gradient(top,#eee,#f9f9f9,#eee);background-image:linear-gradient(top,#eee,#f9f9f9,#eee);padding:1px 3px;font-family:inherit;font-size:.85em}.oembeded .oembed_photo{display:inline-block}img[data-echo]{margin:25px 0;width:100px;height:100px;background:url(../img/ajax.gif) center center no-repeat #fff}.spinner{display:inline-block;width:10px;height:10px;margin-bottom:-.1em;border:2px solid rgba(0,0,0,.5);border-top-color:transparent;border-radius:100%;-webkit-animation:spin 1s infinite linear;animation:spin 1s infinite linear}.spinner:after{content:'';display:block;width:0;height:0;position:absolute;top:-6px;left:0;border:4px solid transparent;border-bottom-color:rgba(0,0,0,.5);-webkit-transform:rotate(45deg);transform:rotate(45deg)}@-webkit-keyframes spin{to{-webkit-transform:rotate(360deg)}}@keyframes spin{to{transform:rotate(360deg)}}p.toc{margin:0!important}p.toc ul{padding-left:10px}p.toc>ul{padding:10px;margin:0 10px;display:inline-block;border:1px solid #ededed;border-radius:5px}p.toc li,p.toc ul{list-style-type:none}p.toc li{width:100%;padding:0;overflow:hidden}p.toc li a::after{content:"."}p.toc li a:before{content:"• "}p.toc h5{text-transform:uppercase}p.toc .title{float:left;padding-right:3px}p.toc .number{margin:0;float:right;padding-left:3px;background:#fff;display:none}input.task-list-item{margin-left:-1.62em}.markdown{font-family:"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;padding:20px}.markdown a{text-decoration:none;vertical-align:baseline}.markdown a:hover{text-decoration:underline}.markdown h1{font-size:2.2em;font-weight:700;margin:1.5em 0 1em}.markdown h2{font-size:1.8em;font-weight:700;margin:1.275em 0 .85em}.markdown h3{font-size:1.6em;font-weight:700;margin:1.125em 0 .75em}.markdown h4{font-size:1.4em;font-weight:700;margin:.99em 0 .66em}.markdown h5{font-size:1.2em;font-weight:700;margin:.855em 0 .57em}.markdown h6{font-size:1em;font-weight:700;margin:.75em 0 .5em}.markdown h1+p,.markdown h1:first-child,.markdown h2+p,.markdown h2:first-child,.markdown h3+p,.markdown h3:first-child,.markdown h4+p,.markdown h4:first-child,.markdown h5+p,.markdown h5:first-child,.markdown h6+p,.markdown h6:first-child{margin-top:0}.markdown hr{border:1px solid #ccc}.markdown p{margin:1em 0;word-wrap:break-word}.markdown ol{list-style-type:decimal}.markdown li{display:list-item;line-height:1.4em}.markdown blockquote{margin:1em 20px}.markdown blockquote>:first-child{margin-top:0}.markdown blockquote>:last-child{margin-bottom:0}.markdown blockquote cite:before{content:'\2014 \00A0'}.markdown .code{border-radius:3px;word-wrap:break-word}.markdown pre{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;overflow:auto;padding:.5em}.markdown pre code{border:0;display:block}.markdown pre>code{font-family:Consolas,Inconsolata,Courier,monospace;font-weight:700;white-space:pre;margin:0}.markdown code{border-radius:3px;word-wrap:break-word;border:1px solid #ccc;padding:0 5px;margin:0 2px}.markdown img{max-width:100%}.markdown mark{color:#000;background-color:#fcf8e3}.markdown table{padding:0;border-collapse:collapse;border-spacing:0;margin-bottom:16px}.markdown table tr td,.markdown table tr th{border:1px solid #ccc;margin:0;padding:6px 13px}.markdown table tr th{font-weight:700}.markdown table tr th>:first-child{margin-top:0}.markdown table tr th>:last-child{margin-bottom:0}.markdown table tr td>:first-child{margin-top:0}.markdown table tr td>:last-child{margin-bottom:0}@import url(http://fonts.googleapis.com/css?family=Roboto+Condensed:300italic,400italic,700italic,400,300,700);.haroopad{padding:20px;color:#222;font-size:15px;font-family:"Roboto Condensed",Tauri,"Hiragino Sans GB","Microsoft YaHei",STHeiti,SimSun,"Lucida Grande","Lucida Sans Unicode","Lucida Sans",'Segoe UI',AppleSDGothicNeo-Medium,'Malgun Gothic',Verdana,Tahoma,sans-serif;background:#fff;line-height:1.6;-webkit-font-smoothing:antialiased}.haroopad a{color:#3269a0}.haroopad a:hover{color:#4183c4}.haroopad h2{border-bottom:1px solid #e6e6e6}.haroopad h6{color:#777}.haroopad hr{border:1px solid #e6e6e6}.haroopad blockquote>code,.haroopad h1>code,.haroopad h2>code,.haroopad h3>code,.haroopad h4>code,.haroopad h5>code,.haroopad h6>code,.haroopad li>code,.haroopad p>code,.haroopad td>code{font-family:Consolas,"Liberation Mono",Menlo,Courier,monospace;font-size:85%;background-color:rgba(0,0,0,.02);padding:.2em .5em;border:1px solid #efefef}.haroopad pre>code{font-size:1em;letter-spacing:-1px;font-weight:700}.haroopad blockquote{border-left:4px solid #e6e6e6;padding:0 15px;color:#777}.haroopad table{background-color:#fafafa}.haroopad table tr td,.haroopad table tr th{border:1px solid #e6e6e6}.haroopad table tr:nth-child(2n){background-color:#f2f2f2}.hljs{display:block;overflow-x:auto;padding:.5em;background:#474949;color:#d1d9e1;-webkit-text-size-adjust:none}.hljs-body,.hljs-collection{color:#d1d9e1}.diff .hljs-header,.hljs-comment,.hljs-doctype,.hljs-javadoc,.lisp .hljs-string{color:#969896;font-style:italic}.clojure .hljs-attribute,.css .hljs-tag,.hljs-addition,.hljs-keyword,.hljs-winutils,.javascript .hljs-title{color:#c9c}.hljs-number{color:#f99157}.hljs-command,.hljs-dartdoc,.hljs-hexcolor,.hljs-phpdoc,.hljs-regexp,.hljs-string,.hljs-tag .hljs-value,.tex .hljs-formula{color:#8abeb7}.hljs-built_in,.hljs-chunk,.hljs-decorator,.hljs-function .hljs-title,.hljs-identifier,.hljs-localvars,.hljs-title{color:#b5bd68}.hljs-class .hljs-keyword{color:#f2777a}.haskell .hljs-label,.hljs-class .hljs-title,.hljs-constant,.hljs-id,.hljs-parent,.hljs-variable,.smalltalk .hljs-number{color:#fc6}.django .hljs-tag .hljs-keyword,.hljs-rules .hljs-property,.hljs-tag .hljs-title{font-weight:700}.hljs-attribute{color:#81a2be}.diff .hljs-change,.hljs-attr_selector,.hljs-cdata,.hljs-important,.hljs-pi,.hljs-pragma,.hljs-preprocessor,.hljs-shebang,.hljs-special,.hljs-subst,.hljs-symbol,.hljs-symbol .hljs-string{color:#f99157}.hljs-deletion{color:#dc322f}.tex .hljs-formula{background:#eee8d5}.MathJax_Hover_Frame{border-radius:.25em;-webkit-border-radius:.25em;-moz-border-radius:.25em;-khtml-border-radius:.25em;box-shadow:0 0 15px #83A;-webkit-box-shadow:0 0 15px #83A;-moz-box-shadow:0 0 15px #83A;-khtml-box-shadow:0 0 15px #83A;border:1px solid #A6D!important;display:inline-block;position:absolute}.MathJax_Hover_Arrow{position:absolute;width:15px;height:11px;cursor:pointer}#MathJax_About{position:fixed;left:50%;width:auto;text-align:center;border:3px outset;padding:1em 2em;background-color:#DDD;color:#000;cursor:default;font-family:message-box;font-size:120%;font-style:normal;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;border-radius:15px;-webkit-border-radius:15px;-moz-border-radius:15px;-khtml-border-radius:15px;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_Menu{position:absolute;background-color:#fff;color:#000;width:auto;padding:2px;border:1px solid #CCC;margin:0;cursor:default;font:menu;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;z-index:201;box-shadow:0 10px 20px gray;-webkit-box-shadow:0 10px 20px gray;-moz-box-shadow:0 10px 20px gray;-khtml-box-shadow:0 10px 20px gray;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}.MathJax_MenuItem{padding:2px 2em;background:0 0}.MathJax_MenuArrow{position:absolute;right:.5em;color:#666}.MathJax_MenuActive .MathJax_MenuArrow{color:#fff}.MathJax_MenuArrow.RTL{left:.5em;right:auto}.MathJax_MenuCheck{position:absolute;left:.7em}.MathJax_MenuCheck.RTL{right:.7em;left:auto}.MathJax_MenuRadioCheck{position:absolute;left:1em}.MathJax_MenuRadioCheck.RTL{right:1em;left:auto}.MathJax_MenuLabel{padding:2px 2em 4px 1.33em;font-style:italic}.MathJax_MenuRule{border-top:1px solid #CCC;margin:4px 1px 0}.MathJax_MenuDisabled{color:GrayText}.MathJax_MenuActive{background-color:Highlight;color:HighlightText}.MathJax_Menu_Close{position:absolute;width:31px;height:31px;top:-15px;left:-15px}#MathJax_Zoom{position:absolute;background-color:#F0F0F0;overflow:auto;display:block;z-index:301;padding:.5em;border:1px solid #000;margin:0;font-weight:400;font-style:normal;text-align:left;text-indent:0;text-transform:none;line-height:normal;letter-spacing:normal;word-spacing:normal;word-wrap:normal;white-space:nowrap;float:none;box-shadow:5px 5px 15px #AAA;-webkit-box-shadow:5px 5px 15px #AAA;-moz-box-shadow:5px 5px 15px #AAA;-khtml-box-shadow:5px 5px 15px #AAA;filter:progid:DXImageTransform.Microsoft.dropshadow(OffX=2, OffY=2, Color='gray', Positive='true')}#MathJax_ZoomOverlay{position:absolute;left:0;top:0;z-index:300;display:inline-block;width:100%;height:100%;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}#MathJax_ZoomFrame{position:relative;display:inline-block;height:0;width:0}#MathJax_ZoomEventTrap{position:absolute;left:0;top:0;z-index:302;display:inline-block;border:0;padding:0;margin:0;background-color:#fff;opacity:0;filter:alpha(opacity=0)}.MathJax_Preview{color:#888}#MathJax_Message{position:fixed;left:1px;bottom:2px;background-color:#E6E6E6;border:1px solid #959595;margin:0;padding:2px 8px;z-index:102;color:#000;font-size:80%;width:auto;white-space:nowrap}#MathJax_MSIE_Frame{position:absolute;top:0;left:0;width:0;z-index:101;border:0;margin:0;padding:0}.MathJax_Error{color:#C00;font-style:italic}footer{position:fixed;font-size:.8em;text-align:right;bottom:0;margin-left:-25px;height:20px;width:100%}</style>
</head>
<body class="markdown haroopad">
<h1 id="latency-analysis"><a name="latency-analysis" href="#latency-analysis"></a>Latency Analysis</h1><p>Latency analysis is provided by the OSATE latency analysis plug-in. The latency analysis is performed on AADL models that include end-to-end flows and calculates minimum and maximum latency taking into a wide range of latency contributors. It does so based on latency budgets assigned to different architectural elements as well as based on design information as architectural designs evolve. The AADL model may range from a functional architecture with latency budgets at different levels of decomposition, to a task and communication architecture with execution rates mapped to a hardware platform supporting partitioning. The fidelity of the analysis is determined by the details in the AADL model. </p><p>The results are reported in a common result format as well as in a spreadsheet format together with the details of each latency contributor. The latency analysis can be parameterized by some preference settings that allow users to explore architectural variations without having to change details in the model, e.g., whether the system behaves as an asynchronous or synchronous system.</p><h2 id="usage,-result-reports,-and-examples"><a name="usage,-result-reports,-and-examples" href="#usage,-result-reports,-and-examples"></a>Usage, Result Reports, and Examples</h2><p>The latency analysis plugin comes pre-installed with OSATE. In this section we describe how the latency analysis is invoked, how the latency results are presented, and a reference to example models. It also describes the preference settings supported by the latency analysis.</p><h3 id="invoking-the-latency-analysis"><a name="invoking-the-latency-analysis" href="#invoking-the-latency-analysis"></a>Invoking the Latency Analysis</h3><p>Latency analysis is performed on AADL instance models. You invoke the analysis by selecting the instance model of interest in the AADL Navigator and then selecting the <strong>Check Flow Latency</strong> command in the main menu <strong>Analyses/Timing</strong>,<br><img src="images/mainmenu.png" alt="main menu" title="main menu"><br>via the context menu by right-clicking on the instance model in the AADL Navigator - again under <strong>Analyses/Timing</strong>,<br><img src="images/contextmenu.png" alt="context menu" title="context menu"><br>or by selecting the instance model and then clicking on the toolbar button for flow latency analysis with the following icon (<img src="images/checkflowlatency.gif" alt="toolbar" title="toolbar">).</p><p>The latency analysis calculates minimum and maximum latency for all end-to-end flows in the instance model. If the instance model has operational modes the analysis is performed for each mode. The latency analysis can be affected by preference settings that allow users </p><h3 id="latency-analysis-result-reports"><a name="latency-analysis-result-reports" href="#latency-analysis-result-reports"></a>Latency Analysis Result Reports</h3><p>Once the latency analysis is finished, a report is produced in a folder called <strong>reports/latency</strong>. The <strong>reports</strong> folder is found in the <strong>instances</strong> folder.<br><img src="images/reportsfolder.png" alt="reports folder" title="reports folder"></p><p>The latency analysis generates the report in spreadsheet format and a common <strong>Result</strong> format. The spreadsheet format is stored as a csv file and as a xls file. Both reports contain the same information but the xls file utilizes Excel formatting features (color-coding of results and separate sheets for different end to end flows).</p><blockquote>
<p>Note: If your installation of Eclipse (OSATE) does not recognize the xls extension, you can add it yourself. Under <strong>Window/Preferences</strong> go to <strong>General/Editors/File</strong> associations and add *.xls as file type, and then for this selected file type associate the editor by clicking on Add select External programs and pick the Microsoft Excel Worksheet.</p>
</blockquote><p>The <strong>Result</strong> XMI format provided by OSATE and uses the file extension <strong>result</strong>. That format is based on an Ecore model and facilitates post-processing by tools. It is described in a later section.</p><p>The report name consists of the name of the instance model, the label <strong>latency</strong> and an indication of<br>the preference settings that were used to perform the latency analysis (using the two letter labels explained in the <strong>Latency Analysis Preference</strong> section). </p><blockquote>
<p>The inclusion of the preference settings in the file name allows users can compare results under different preference settings.</p>
</blockquote><h3 id="latency-analysis-report-content"><a name="latency-analysis-report-content" href="#latency-analysis-report-content"></a>Latency Analysis Report Content</h3><p>The latency analysis result report consists of separate detailed reports for each end-to-end flow and for each operational mode if the AADL model includes mode specifications. An example of such a report in spreadsheet format is shown.<br><img src="images/latencyresult.png" alt="report spreadsheet" title="report spreadsheet"><br>The header of each report identifies the name of the end-to-end flow being analyzed, the component implementation that contains the end-to-end flow declaration, the operational mode being analyzed (if modes are declared), and the preference settings used. </p><p>Each report includes a separate entry for each latency contributor: </p><ul>
<li>Components contribute processing latency and sampling or queuing latency. Sampling latency is affected by whether connections are declared to be immediate (mid-frame) or (frame) delayed.</li><li>Connections contribute communication latency. It is determined by the components (virtual bus, hardware components) that the connection is bound to.</li><li>Partitions, if present, contribute partition output latency and latency in terms of major frame offset.</li></ul><p>Each contributor entry has a number of columns:</p><ol>
<li>the type and name of the <strong>contributor</strong></li><li>the <strong>minimum specified</strong> latency as indicated by the latency property value associated with the contributor. (The latency property takes a range value and the lower bound is used as minumum).</li><li>the <strong>minimum actual</strong> latency value used by the analysis. This value is determined by properties in the architecture design, e.g., the period and execution time of a thread, or the transmission time by a bus. If no actual value can be determined the specified value is used.</li><li>the <strong>minimum method</strong> used to determine the minimum actual value. The labels are:<br>— <strong>no latency</strong>: the value zero as no latency contribution was specified or computed from the model<br>— <strong>specified</strong>: use of the specified latency property value<br>— <strong>processing time</strong>: processing related latency contribution of a component based on compute execution time and deadline<br>— <strong>transmission time</strong>: latency contribution for a connection. Uses on binding to a virtual bus or bus using latency property values of those components or based transmission time computation based on data size property values of the data being transmitted if Transmission_Time and Data_Size have been specified<br>— <strong>queued</strong> latency contribution due to queuing. Uses on queue size, execution time, and period property values<br>— <strong>sampling</strong> latency contribution due to a component sampling periodically. Uses period property values. This value may differ in synchronous and asynchronous system settings<br>— <strong>first sampling</strong> latency contribution. Uses period property values. Not sensitive to a/synchronous system<br>— <strong>delayed sampling</strong> latency contribution contribution due delayed connection. Uses period property values<br>— <strong>sampling protocol/bus</strong> latency contribution due to periodic bus protocol. Uses period property values<br>— <strong>partition major frame</strong> latency contribution due to periodic execution of a partition. Uses major frame from ARINC653 schedule or period property of virtual processor representing the partition<br>— <strong>partition output</strong> latency contribution due to delay in output to end of partition (PE) or major frame (MF). Uses property values from ARINC653 partition schedule<br>— <strong>partition offset</strong> latency contribution due to partition offset in the partition schedule, either from beginning of major frame or earlier partition in the same schedule. Uses property values from ARINC653 partition schedule</li><li>the <strong>maximum specified</strong>, <strong>maximum actual</strong>, <strong>maximum subtotals</strong>, and <strong>maximum method</strong> columns describe the maximum latency contribution</li><li>the <strong>comments</strong> column provides additional details on the calculations and may give warnings or error messages to report inconsistencies.</li></ol><blockquote>
<p>If connections are bound to virtual buses and buses, then those components are shown in parentheses “()”. Their latency numbers add up to the latency number shown as actual for the connection.</p>
<p>Further details about how the actual latency value is calculated are provided in the sections below.</p>
</blockquote><p>Each end-to-end latency report entry shows the computed totals in a row labelled <strong>Latency Total</strong> (row 9 in the example). It shows the total for the specified values as well as the total for the actual values.  In the row labelled <strong>Specified End To End Latency</strong> the report shows the expected end-to-end latency as specified by the latency property value associated with the end-to-end flow.</p><p>This is followed by a summary of the results labelled <strong>End to end Latency Summary</strong>.<br>In the summary the computed totals of specified and actual latency contributions for the minimum and maximum latency are compared against the expected end to end latency and an appropriate message (success, warning or error message) is included. The summary also compares the actual latency variation between the minimum and maximum exceeds the variation in the expected end to end latency variation specified by the latency range value associated with the end to end flow.</p><h3 id="examples"><a name="examples" href="#examples"></a>Examples</h3><p>The latency case study example can be found at <a href="http://www.github.com/osate/examples/latency-case-study">http://www.github.com/osate/examples/latency-case-study</a>. There is a paper describing this case study at <a href="http://e-archivo.uc3m.es/bitstream/handle/10016/19688/incremental_REACTION_2014.pdf">http://e-archivo.uc3m.es/bitstream/handle/10016/19688/incremental_REACTION_2014.pdf</a>. In this case study we go through a progression from a functional architecture with latency budgets to a task and communication architecture that represents the application using the sampled processing paradigm and its deployment on various hardware platforms.</p><p>The stepper motor case satudy example can be found at <a href="https://github.com/osate/examples/tree/master/StepperMotor">https://github.com/osate/examples/tree/master/StepperMotor</a>. There is an SEI Technical Report that describes the case study in detail <a href="http://repository.cmu.edu/cgi/viewcontent.cgi?article=1826&amp;context=sei">http://repository.cmu.edu/cgi/viewcontent.cgi?article=1826&amp;context=sei</a> and in a conference paper <a href="https://hal.archives-ouvertes.fr/hal-01292322/">https://hal.archives-ouvertes.fr/hal-01292322/</a>. In this case study latency analysis is used as one of the analytical tools to diagnose a problem in an engine control system and to evaluate several design alternatives.</p><p>Several other examples and references to their documenation can be found at <a href="https://github.com/osate/alisa-examples">https://github.com/osate/alisa-examples</a>.<br>The situational awareness system example illustrates the use of latency analysis to determine the latency contribution of two pull protocols to confirm the specified latency value in the virtual bus representation of the protocol.<br>The simple control system example has a multi-tier model of a control system application organized into two processes with two threads each and deploys it on a variatiety of hardware configurations.<br>The multi-tier aircraft example illustrates the evolution of an aircraft system across multiple tiers. The latency analysis highlights how design decisions in the evolving architecture affect end-to-end latency.</p><h2 id="preference-settings-for-latency-analysis"><a name="preference-settings-for-latency-analysis" href="#preference-settings-for-latency-analysis"></a>Preference Settings for Latency Analysis</h2><p>The latency analysis offers several preference settings that affect how latency is calculated. This allows users to perform trade studies along certain dimensions without changing the model. The preference settings can be found under the menu <strong>Window/Preferences</strong> then <strong>OSATE Preferences/Flow Analysis</strong>.<br><img src="images/preferencesettings.png" alt="preference settings" title="preference settings"></p><p>The latency analysis supports the following settings:</p><ul>
<li><strong>Treat as synchronous or asynchronous system</strong>. Used to assess the sampling latency between periodic components that are not inherently synchronous (threads or partitions on the same processor) or explicitly specified as synchronous by referring to the same <em>Reference_Time</em> property value.  <ul>
<li><strong>Asynchronous system (AS) [default]</strong>: The components are not<br>time synchronized, i.e., dispatches may have time shift.</li><li><strong>Synchronous system (SS)</strong>: The components are time<br>synchronized, i.e., periodic dispatches are aligned<br>across systems.</li></ul>
</li><li><strong>Partition output policy</strong>. Used to reflect latency contribution by<br>inter-partition communication due to different inter-communication policies in partitioned systems.<ul>
<li><strong>Major Frame delayed (MF) [default]</strong>: assume that<br>inter-partitions connections are flushed/realized at the end of<br>the major frame. If a task in partition A sends a data to a task<br>in partition B, the fresh data will be available only after<br>completion of all remaining partitions, regardless the execution<br>order of partition A or partition B.</li><li><strong>Partition End (PE)</strong>: assume that inter-partitions connections<br>are available at the end of the partition whose task sends data.<br>If a task in partition A sends a data to a task in partition B,<br>the later will receive the data in the same major frame if<br>partition B is executed after partition A.</li></ul>
</li><li><strong>Worst-case processing time</strong>: Users can choose between deadline<br>and worst-case execution time as worst case processing time. For best case we always use execution time.<ul>
<li><strong>Deadline (DL) [default]</strong>: Deadline represents the worst-case completion time assuming the tasks are schedulable.</li><li><strong>Maximum Compute Execution Time (ET)</strong>: Maximum compute execution time is useful when processing time is considered without resource scheduling. </li></ul>
</li><li><strong>Queuing latency on incoming ports</strong>: Affects how the best case<br>queuing delay is determined. For worst-case we always use full queue.<ul>
<li><strong>Assume empty queue (EQ) [default]</strong>: No delay as the queue<br>is assumed to be empty.</li><li><strong>Assume full queue (FQ)</strong>: Use minimum compute execution time<br>times the queue size to determine the best case queuing time.</li></ul>
</li></ul><h2 id="latency-contributors-and-relevant-properties"><a name="latency-contributors-and-relevant-properties" href="#latency-contributors-and-relevant-properties"></a>Latency Contributors and Relevant Properties</h2><p>Latency analysis takes a range of latency contributors into account when calculating minimum and maximum latency for an end to end flow. Latency contributions may be latency budgets assigned to different elements in an end to end flow, i.e., to flow specifications of components and to connections. Once the AADL model reflects aspects of an architecture design, latency contributions based on design decisions are taken into consideration. They include processing time by components, sampling delay in sampled processing sceanarios or queuing delay in message based processing scenarios, partition delays when ARINC653 partitions are used, communication latency contributions by buses/networks and protocols.</p><p>In this section we describe how different latency contributions are determined based on relevant property values in the AADL model.</p><h3 id="latency-budgets-specified-via-latency-property"><a name="latency-budgets-specified-via-latency-property" href="#latency-budgets-specified-via-latency-property"></a>Latency Budgets Specified via Latency Property</h3><p>The <strong>latency</strong> property allows user to associate a latency value with flow specifications of components and with connections that effectively represents a latency budget. It takes a time range value whose bounds represent minimum and maximum latency. It can be associated with</p><ul>
<li>flow specifications (flow sources, flow paths, and flow sinks) of components to represent processing latency contributed by the component.</li><li>connections to represent communication latency.</li></ul><p>Users can perform end-to-end latency analysis on a system based on these latency budget specifications. They can do so for a system with one layer of subsystems, or subsystems expanded by additional layers of the architecture hierarchy. Different subsystems can be expanded to different levels of the hierarchy. Examples of such models are representing conceptual, functional, and task architectures. The analysis result ensures that latency budgets assigned to various components due not exceed expected end-to-end latencies as specified by the latency property on various end to end flows.</p><p>The analysis will calculate the minimum and the maximum end-to-end latency by adding up the specified latencies of all the component flow specifications and of the connections. Absence of a latency property on connections or flow specifications is interpreted as a latency value of zero (marked as <strong>no latency</strong> in the report). </p><p>The latency analysis report will identify if a latency budget assigned at a flow specification of an eclosing component is exceeded by the budgets assigned to elements included in a flow implementation.</p><h3 id="queuing-delay-in-message-based-processing"><a name="queuing-delay-in-message-based-processing" href="#queuing-delay-in-message-based-processing"></a>Queuing Delay in Message-based Processing</h3><p>An application may perform message based processing. In AADL terms this means that messages arrive at event data ports or events arrive at event ports. These ports are considered queued ports. The queue size is specified by the <em>Queue_Size</em> property.</p><p>Latency analysis adds queuing delay as latency contribution only if the user has explicitly assigned a queue size to the destination port of a connection.</p><p>The worst-case queuing delay assumes a full queue, i.e., is the product of queue size and worst-case processing time. For worst-case processing time the deadline is used and if not present the latency value of the flow specification. A preference setting allows the user to specify that worst-case execution time should be used instead of deadline. </p><p>The best-case queuing delay by default assumes an empty queue. However, in a preference setting the user can specify a full queue is to be assumed. In this case the queue size is multiplied by the best-case execution time.</p><p>Users may specify functional architectures with queuing ports, i.e., event ports and event data ports may be associated with system or abstract components. If the ports have a queue size property value greater than zero queuing latency is added by the latency analysis. </p><blockquote>
<p>If users have not specified a deadline on the component the latency value associated with the flow specification is multiplied by th equeue size.</p>
</blockquote><p>In a task and communication architecture users may have specified devices and threads with queuing ports. In this case the deadline or worst-case execution time is used </p><blockquote>
<p>In the case of a periodic or sporadic task with a queue the period is used instead of the worst-case or best-case execution time to reflect the fact that queue processing is paced at the rate specified by the period.</p>
<p>In the case of a periodic or sporadic task with a queue the queue size is reduced by one in calculating the queuing latency to reflect the fact that the sampling latency of the periodic recipient accounts for one element.</p>
</blockquote><h3 id="sampling-delay-in-periodic-sampled-processing"><a name="sampling-delay-in-periodic-sampled-processing" href="#sampling-delay-in-periodic-sampled-processing"></a>Sampling Delay in Periodic Sampled Processing</h3><p>In embedded systems it is common to perform periodic sampled processing. Examples are displays refreshing at a specified rate, sensors sampling the physical environment at a given rate, application systems processing their input periodically (periodic threads). This can result in a sampling delay as latency contribution, i.e., the amount of time incoming data is in the incoming port until the component is dispatched.</p><p>The <strong>Period</strong> property allows users to specify the time interval at which a component executes. We can annotate a system, abstract, process, thread group, thread, device component with a period. </p><p>We assume that the worst-case sampling latency contribution is the period, i.e., the recipient sampled just before the new value arrives, and the best-case sampling latency is zero, i.e., the new value arrives just before the recipient samples. </p><p>Users can also refine their functional architecture by indicating periodic processing by cetain components with a period property value. Alternatively, users may have developed a task and communication architecture ansd associate period property values with threads and devices.</p><blockquote>
<p>In the case of sampled processing we distinguish between <strong>synchronous</strong> and <strong>asynchronous</strong> system scenario when both the sender and receiver execute periodically. In the synchronous case the sending and receiving periodic task are dispatched by the same clock, thus, the sampling delay may be less than a full period (see discussion below).  </p>
</blockquote><h3 id="processing-times-as-latency-contributors"><a name="processing-times-as-latency-contributors" href="#processing-times-as-latency-contributors"></a>Processing Times as Latency Contributors</h3><p>Users may have specified a <strong>Deadline</strong> property value for components. This property value represents the upper bound of worst-case completion time as long as the component is deemed as schedulable. </p><p>Users can specify <strong>Compute_Execution_Time</strong> property values for threads and devices. </p><p>The minimum value of <strong>Compute_Execution_Time</strong> is used as best-case latency contribution.</p><p>The latency analysis uses explicitly assigned <strong>Deadline</strong> value as worst-case latency contribution. </p><blockquote>
<p>The latency analysis tool only considers explicitly set Deadline values. The default value of the Deadline is that of the Period value and is ignored by the latency analysis.</p>
</blockquote><p>Users can change the preference setting to use the worst-case Compute_Execution_Time (<strong>ET</strong> setting) instead of the Deadline (<strong>DL</strong> setting).</p><blockquote>
<p>The compute execution time value does not necessarily represent the worst-case completion time. Users may specify a worst-case completion time through the Dealine property. In the future we will interface with scheduling analysis results to retrieve completion times.   </p>
</blockquote><p>The flow specification latency is used as processing latency contribution if the execution time (in ET) or deadline (in DL) is not set.</p><h3 id="sampled-processing-in-synchronous-system-scenarios"><a name="sampled-processing-in-synchronous-system-scenarios" href="#sampled-processing-in-synchronous-system-scenarios"></a>Sampled Processing in Synchronous System Scenarios</h3><p>We may have a <strong>synchronous system</strong> scenario where both the sending and receiving task are dispatched according to the same clock. In this case, the sampling latency can be smaller. The second sampling unit is dispatched at the same time as the first sampling unit, i.e., their dispatch times are aligned. In this case, the sampling latency contribution is the difference between any processing and communication latency since the first sampling unit and the next period of the second sampling unit - effectively rounding up to the next period. The first sampling unit may be followed by non-sampling units before the second sampling unit. In this case the sum of processing and communication latencies is rounded up.</p><blockquote>
<p>The effect of sampling in a synchronized system context is that the sampling latency contribution evens out any variation in cumulative latency of incoming data, i.e., it acts as jitter buffer. For example, a periodic (I/O) task is sampling sensor input. The input is then processed by non-sampling tasks to minimize latency. To manage the cumulative latency variation (jitter) the output is sent to the actuator by the same I/O task at the beginning of the next frame. </p>
<p>The cumulative processing and communication latency for the best case and worst case may round up to different multiples of sampling frames (period of the second sampling task). This results in frame-level jitter even if the min/max cumulative processing latency differs only by a few micro seconds, e.g., if one value just below and the other just above a multiple of the sampling frame.</p>
</blockquote><p>Different physical components, e.g., devices, processors, and buses are considered to operate asynchronously unless they have asigned the same <strong>Referemce_Time</strong> property value. </p><p>Software components bound to the same processor are considered to operate synchronously. Software components bound to different processor are considered to operate synchronously if the two processors have the same value for the <strong>Referemce_Time</strong> property.</p><p>A preference setting lets users choose whether components that have no indication of being synchronized, i.e., on the same processor, or are inherently asynchronous, i.e., different hardware components, should be handled as if synchronous or asynchronous. This setting applies only to components that have not been explicitly identified as synchronous via the <strong>Referemce_Time</strong> property, or software components bound to the same processor.</p><h3 id="mid-frame-and-frame-delayed-communication"><a name="mid-frame-and-frame-delayed-communication" href="#mid-frame-and-frame-delayed-communication"></a>Mid-frame and Frame-delayed Communication</h3><p>The AADL thread model supports specification of immediate, and delayed connections between periodically sampling components.</p><ul>
<li>An immediate connection means that although both tasks have the same dispatch time the second tasks waits for the completion of the first task. This corresponds to mid-frame communication in a Simulink control model.</li><li>A delayed connection means that the second task always receives the output in the next sampling period, i.e., it is always frame-delayed. This ensures that for both the minimum latency and maximum latency we have a sampling latency of the second task period.</li></ul><blockquote>
<p>Immediate and delayed connection assure deterministic up and down sampling of tasks with harmonic periods. This means that a sensor providing readings at 50ms to a processing task operating at 100ms, the processing task will always see every other signal (or if the signals are queued will always see two signals in the queue). The effect is that this sampling pattern does not introduce additional noise into the signal.</p>
</blockquote><p>In a sequence of periodic tasks with immediate connections the deadline of the last task becomes the deadline of the sequence. For worst-case latency contribution this deadline is used. For best-case latency contribution the sum of minimum compute execution times is used. </p><blockquote>
<p>The cumulative completion times must be within the deadline.</p>
</blockquote><p>If the deadline or cumpute execution time is not specified, the sum of maximum flow specification latencies is used for best/worst-case latency contribution.</p><blockquote>
<p>A sequence of periodic tasks with immediate connections is similar to a periodic task followed by data-driven (aperiodic) tasks. The difference is that in the case of a sequence of aperiodic tasks each task execution time has to meet its own deadline, i.e., the cumulative maximum processing latency is bounded by the sum of task deadlines rather than the deadline of the last task.</p>
</blockquote><p>Delayed connections always add a delay to the next frame as latency contribution. </p><blockquote>
<p>Connections between periodic tasks are considered to be sampling connections if not specified as immediate or delayed connection. This means that a receiving periodic task may sample the old or the new value depending on the completion/send time of the sender. This may lead to frame-level latency jitter.</p>
</blockquote><h3 id="communication-latency-contribution-by-networks/buses-and-protocols"><a name="communication-latency-contribution-by-networks/buses-and-protocols" href="#communication-latency-contribution-by-networks/buses-and-protocols"></a>Communication Latency Contribution by Networks/Buses and Protocols</h3><p>In this section we discuss how latency contributions can be associated with communication transfer mechanisms that connections are bound to, i.e., virtual buses, buses, device, systems, and abstract components.</p><h4 id="communication-latency-specifications-for-protocols-and-networks/buses"><a name="communication-latency-specifications-for-protocols-and-networks/buses" href="#communication-latency-specifications-for-protocols-and-networks/buses"></a>Communication Latency Specifications for Protocols and Networks/Buses</h4><p>Users can indicate the intended transport mechanism via the <strong>Actual_Connection_Binding</strong> property or <strong>Required_Virtual_Bus_Class</strong> property.</p><p>The latency analysis will take into account every element of an <em>Actual_Connection_Binding</em> as latency contributor. In the case of a virtual bus the analysis also includes the entities that the virtual bus is bound to according to its <em>Actual_Connection_Binding</em> property value. If the virtual bus or connection does not have a specified <em>Actual_Connection_Binding</em> property value, then the <em>Required_Virtual_Bus_Class</em> property values are interpreted as latency contributors.</p><p>A bus or virtual bus can have a <strong>Transmission_Time</strong> property value. It specifies a fixed time and a per byte time latency contribution. If this property is present and the sending port has a data type with a <em>Data_Size</em> property value, then the communication latency contribution is calculated from these values. </p><p>The <em>Transmission_Time</em> property on a hardware component indicates the actual transfer time. For a virtual bus the transmission time represents any computational latency by the protocol, which may be dependent on the size of the data being processed.</p><blockquote>
<p>The fixed time portion of Transmission_Time can be used to reflect worst-case queuing delays in the transfer.</p>
</blockquote><p>A virtual bus or bus may add protocol wrapper data to be transmitted, which is specified by a <strong>Data_Size</strong> property on the virtual bus or bus. This will be added to the size of the application data when used in computing the transmission time.</p><p>If <em>Transmission_Time</em> is not present, the <strong>Latency</strong> property value associated with the virtual bus, bus, or other component the connection is bound to, is used.</p><p>If neither <em>Transmission_Time</em> nor <em>Latency property</em> is specified for the bus or virtual bus then no latency contribution is assumed. </p><p>More than one protocol may be involved in the connection communication, e.g., one protocol may use a second protocol to perform its transfer. The latency analysis adds each of the protocol latency contributions to the total. This allows users to specify latency overhead being added by each protocol. </p><blockquote>
<p>If the connection has no binding, but the connection end points are bound or are devices, then the latency analysis attempts to determine the buses that connect the two hardware components between the endpoints.</p>
</blockquote><p>If the connection has no connection binding or required virtual bus, or those contributions are zero, then the <strong>Latency</strong> property value attached to a connection is used as latency contribution.</p><h4 id="periodically-sampling-buses-and-protocols-(virtual-buses)"><a name="periodically-sampling-buses-and-protocols-(virtual-buses)" href="#periodically-sampling-buses-and-protocols-(virtual-buses)"></a>Periodically Sampling Buses and Protocols (virtual buses)</h4><p>Buses and virtual buses may operate periodically. For example, a CANBus operates on a static time line with fixed slots for different transfer actions. This is specified by associating a <strong>Period</strong> property value with a virtual bus, bus, or other component acting as transfer mechanism. In this case a sampling latency is added for every connection that is bound to such a bus.</p><blockquote>
<p>When reflecting the sampling effect of communication the rules for asynchronous and synchronous sampling latency calculation and for determining whether synchronous sampling occurs apply here as well. In the synchronous case sampling latency contribution may be reduced from the full sampling period.</p>
<p>When several protocols or the bus have a sampling period specified, the largest sampling period is used as it determines the transmission rate.</p>
</blockquote><h3 id="partitioned-systems"><a name="partitioned-systems" href="#partitioned-systems"></a>Partitioned Systems</h3><p>Partitioned systems use the concept of virtual machine (represented by AADL virtual processor) to enforce address space protection of processes at runtime.<br>The user can use virtual processors to represent partitions. Virtual processors can be declared as subcomponents of processors, or they can be bound to processor. The latency analysis tools handles both<br>modeling styles.</p><p>The user can specify <strong>ARINC653::Module_Major_Frame</strong> on a processor to which partitions are bound to indicate the rate at which partitions are scheduled. </p><p>The user can also specify a full partition schedule using the <strong>ARINC653::Module_Schedule</strong> property, whose value is a list of records with the <strong>Partition</strong> field referring to the partition and the <strong>Duration</strong> field indicating the window size.</p><p>The latency analysis will use the ARINC653 partition schedule information, or the ARINC653 major frame information if the schedule is absent.</p><p>Partitions contribute two types of latency: <strong>partition output delay</strong>, and <strong>partition start delay</strong>.</p><p><em>Partition output delay</em> is due to the partition flushing its output at the <strong>major frame</strong> or at <strong>partition end</strong>.</p><p><em>Partition start delay</em> is due to a partition being scheduled in a particular partition schedule window, or because of the alignment of the partition major frame. In the latter case the latency analysis distinguishes between synchronous and asynchronous cross-partition communication. The same rules about alignment calculation as for sampled processing apply.</p><p>A preference setting lets the user choose the partition <em>major frame</em> or the <em>partition end</em> as the time at which the output is flushed.</p><p>The latency of tasks within a single partition are calculated as before. However, when communication occurs across a partition boundary, communication is delayed until the next frame - determined by the partition period, or until the partition end output and the alignment between the sending and receiving partition - using the partition schedule or major frame property values.</p><blockquote>
<p>A thread may have a period that is a multiple of the partition major frame. The latency analysis takes into account the additional sampling delay of the thread.</p>
<p>Choosing the major frame as partition output assures that end to end latency is not affected by a change in the order in which partitions are allocated to a processor.</p>
</blockquote><h3 id="latency-analysis-and-modes"><a name="latency-analysis-and-modes" href="#latency-analysis-and-modes"></a>Latency Analysis and Modes</h3><p>Latency analysis takes into account modes. It executes the analysis for each of the modes. If you have mode-specific end-to-end flows or mode-specific property values you will get mode-specific results.</p><blockquote>
<p>The analysis is currently not smart enough to avoid executing for all possible modes if and end-to-end flow is not affected by modes.</p>
</blockquote>

<footer style="position:fixed; font-size:.8em; text-align:right; bottom:0px; margin-left:-25px; height:20px; width:100%;">generated by <a href="http://pad.haroopress.com" target="_blank">haroopad</a></footer>
</body>
</html>
